# server.py
from flask import Flask, request, jsonify
import joblib
import zipfile
import os

app = Flask(__name__)

# ===============================
# 1. Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª
# ===============================
ZIP_PATH = "rf_model_4features.zip"    # Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„Ù€ zip
MODEL_PATH = "rf_model_4features.pkl"  # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
SCALER_PATH = "scaler_4features.pkl"   # Ø§Ù„Ø³ÙƒØ§Ù„Ø±
PROTO_ENCODER_PATH = "protocol_encodr.pkl"  # â† Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
TARGET_ENCODER_PATH = "target_encoder.pkl"

# ===============================
# 2. ÙÙƒ Ø§Ù„Ø¶ØºØ· (Ø¥Ø°Ø§ Ù„Ø§Ø²Ù…)
# ===============================
if not os.path.exists(MODEL_PATH):
    with zipfile.ZipFile(ZIP_PATH, "r") as zip_ref:
        zip_ref.extractall(".")

# ===============================
# 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
# ===============================
model = joblib.load(MODEL_PATH)
scaler = joblib.load(SCALER_PATH)
le_protocol = joblib.load(PROTO_ENCODER_PATH)
le_target = joblib.load(TARGET_ENCODER_PATH)

# ===============================
# 4. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ÙŠØ©
# ===============================
@app.route("/", methods=["GET"])
def home():
    return jsonify({
        "message": "ğŸš¦ Traffic ML API is running!",
        "endpoints": {
            "/": "ÙˆØ§Ø¬Ù‡Ø© ØªØ±Ø­ÙŠØ¨ÙŠØ©",
            "/predict": "Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ© (srcPort, dstPort, protocol, size) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆÙ‚Ø¹"
        },
        "example": {
            "srcPort": 12345,
            "dstPort": 80,
            "protocol": "tcp",  # â† Ù†Øµ (Ø³ÙŠØªÙ… ØªØ±Ù…ÙŠØ²Ù‡)
            "size": 512
        }
    })

# ===============================
# 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªÙˆÙ‚Ø¹
# ===============================
@app.route("/predict", methods=["POST"])
def predict():
    data = request.json

    # ØªØ±Ù…ÙŠØ² Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„
    protocol_val = le_protocol.transform([str(data.get("protocol", "tcp"))])[0]

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù€ features (4 ÙÙ‚Ø·)
    features = [[
        data.get("srcPort", 0),
        data.get("dstPort", 0),
        protocol_val,
        data.get("size", 0)
    ]]

    # Scaling
    features_scaled = scaler.transform(features)

    # ØªÙˆÙ‚Ø¹
    pred = model.predict(features_scaled)[0]
    label = le_target.inverse_transform([pred])[0]

    response = {
        "label": label,                     # Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        "isValid": (label == "normal"),     # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·Ø¨ÙŠØ¹ÙŠ
        "color": "green" if label == "normal" else "red"
    }
    return jsonify(response)

# ===============================
# 6. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ±
# ===============================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
